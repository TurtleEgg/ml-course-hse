{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка данных и функции потерь в линейной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные\n",
    "На семинаре мы будем работать с набором данных [Automobile Data Set](https://archive.ics.uci.edu/ml/datasets/Automobile). В данных присутствуют категориальные, целочисленные и вещественнозначные признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_raw = pd.read_csv(\"cars.csv\", header=None, na_values=[\"?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>164.0</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.8</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>164.0</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>4wd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.4</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1            2    3    4     5            6    7      8     9   ...  \\\n",
       "0   3    NaN  alfa-romero  gas  std   two  convertible  rwd  front  88.6  ...   \n",
       "1   3    NaN  alfa-romero  gas  std   two  convertible  rwd  front  88.6  ...   \n",
       "2   1    NaN  alfa-romero  gas  std   two    hatchback  rwd  front  94.5  ...   \n",
       "3   2  164.0         audi  gas  std  four        sedan  fwd  front  99.8  ...   \n",
       "4   2  164.0         audi  gas  std  four        sedan  4wd  front  99.4  ...   \n",
       "\n",
       "    16    17    18    19    20     21      22  23  24       25  \n",
       "0  130  mpfi  3.47  2.68   9.0  111.0  5000.0  21  27  13495.0  \n",
       "1  130  mpfi  3.47  2.68   9.0  111.0  5000.0  21  27  16500.0  \n",
       "2  152  mpfi  2.68  3.47   9.0  154.0  5000.0  19  26  16500.0  \n",
       "3  109  mpfi  3.19  3.40  10.0  102.0  5500.0  24  30  13950.0  \n",
       "4  136  mpfi  3.19  3.40   8.0  115.0  5500.0  18  22  17450.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных\n",
    "Предобработка данных важна при применении любых методов машинного обучения, а в особенности для линейных моделей. В sklearn предобработку удобно делать с помощью модуля [preprocessing](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразование нечисловых признаков\n",
    "Практически все методы машинного обучения требуют, чтобы на вход функции обучения подавалась вещественная матрица. В процессе обучения используются свойства вещественных чисел, в частности, возможность сравнения и применения арифметических операций. Поэтому, даже если формально в матрице объекты-признаки записаны числовые значения, нужно всегда анализировать, можно ли относиться к ним как к числам. \n",
    "\n",
    "__Пример:__ некоторые признаки могут задаваться целочисленными хешами или id (например, id пользователя соц. сети), однако нельзя сложить двух пользователей и получить третьего, исходя из их id (как это может сделать линейная модель).\n",
    "\n",
    "Это пример категориального признака, принимающего значения из неупорядоченного конечного множества $K$. К таким признакам обычно применяют [one-hot encoding](http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features) (вместо одного признака создают $K$ бинарных признаков - по одному на каждое возможное значение исходного признака). В sklearn это можно сделать следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для удобства работы с нашим датасетом создаем маску, указывающую на столбцы с категориальными признаками\n",
    "cat_features_mask = (X_raw.dtypes == \"object\").values # категориальные признаки имеют тип \"object\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# кодирование категорий-строк натуральными числами\n",
    "label_enc = preprocessing.LabelEncoder()\n",
    "for feature in X_raw.columns[cat_features_mask]: \n",
    "    X_raw[feature] = label_enc.fit_transform(X_raw[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>5</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>5</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>94.5</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>5</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>164.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99.8</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>5</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>164.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99.4</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>5</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1   2   3   4   5   6   7   8     9   ...   16  17    18    19  \\\n",
       "0   3    NaN   0   1   0   1   0   2   0  88.6  ...  130   5  3.47  2.68   \n",
       "1   3    NaN   0   1   0   1   0   2   0  88.6  ...  130   5  3.47  2.68   \n",
       "2   1    NaN   0   1   0   1   2   2   0  94.5  ...  152   5  2.68  3.47   \n",
       "3   2  164.0   1   1   0   0   3   1   0  99.8  ...  109   5  3.19  3.40   \n",
       "4   2  164.0   1   1   0   0   3   0   0  99.4  ...  136   5  3.19  3.40   \n",
       "\n",
       "     20     21      22  23  24       25  \n",
       "0   9.0  111.0  5000.0  21  27  13495.0  \n",
       "1   9.0  111.0  5000.0  21  27  16500.0  \n",
       "2   9.0  154.0  5000.0  19  26  16500.0  \n",
       "3  10.0  102.0  5500.0  24  30  13950.0  \n",
       "4   8.0  115.0  5500.0  18  22  17450.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/turtleegg/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# применение one-hot ecnoding\n",
    "enc = preprocessing.OneHotEncoder(sparse=False)\n",
    "X_cat_np = enc.fit_transform(X_raw[X_raw.columns[cat_features_mask]])\n",
    "X_cat_pd = pd.DataFrame(data=X_cat_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205, 61)\n"
     ]
    }
   ],
   "source": [
    "print(X_cat_pd.shape)\n",
    "#X_cat_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следует заметить, что в новой матрице очень много нулевых значений. Чтобы не хранить их в памяти, можно задать параметр OneHotEncoder(sparse = True), и метод fit_transform вернет [разреженную матрицу](http://docs.scipy.org/doc/scipy/reference/sparse.html), в которой хранятся только ненулевые значения. Выполнение некоторых операций с такой матрицей может быть неэффективным, однако большинство методов sklearn умеют работать с разреженными матрицами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вопрос:__ какая проблема возникнет при применении такого способа кодирования для обучения линейной регрессии?\n",
    "    \n",
    "Необходимо удалить один из столбцов, созданных для каждого признака (его легко вычислить из остальных):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_cat_pd.drop(enc.feature_indices_[:-1], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо категориальных, преобразования требуют, например, строковые признаки. Их можно превращать в матрицу частот слов [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), матрицу частот буквосочетаний фиксированной длины, можно извлекать другие признаки (например, длина строки)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заполнение пропусков\n",
    "В матрице объекты-признаки могут быть пропущенные значения, и это вызовет исключение при попытке передать такую матрицу в функцию обучения модели. Если пропусков немного, можно удалить объекты с пропусками из обучающей выборки. Заполнить пропуски можно разными способами:\n",
    "* заполнить средними (mean, median);\n",
    "* предсказывать пропущенные значения по непропущенным.\n",
    "\n",
    "Последний вариант сложный и применяется редко. Замена пропусков средними в вещественных признаках:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_real = X_raw[X_raw.columns[~cat_features_mask]]\n",
    "mis_replacer = preprocessing.Imputer(strategy=\"mean\")\n",
    "X_no_mis = pd.DataFrame(data=mis_replacer.fit_transform(X_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_no_mis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всегда нужно осознавать, случайны ли пропуски в каком-то признаке. Иногда факт отсутствия информации о значении признака может сам быть важным признаком, который необходимо добавить к другим признакам.\n",
    "\n",
    "__Пример:__ предсказание возраста пользователя по данным с его телефона. Поскольку люди старшего возраста чаще пользуются простыми телефонами, факт отсутствия каких-то данных (например, истории посещенных интернет-страниц), скорее всего, будет хорошим признаком.\n",
    "\n",
    "Для категориальных признаков рекомендуется создавать отдельную категорию, соответствующую пропущенному значению. В наши данных пропусков в категориальных признаках нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# проверка пропусков в категориальных признаках\n",
    "np.any(np.isnan(X_cat_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# проверка пропусков после применения Imputer\n",
    "np.any(X_no_mis.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Масштабирование признаков\n",
    "При начале работы с данными всегда рекомендуется приводить все признаки к одному масштабу.  Это важно по нескольким причинам:\n",
    "* ускорение обучения модели (пояснение на лекции);\n",
    "* улучшение численной устойчивости при работе с матрицей объекты-признаки (рядом с нулем чисел с плавающей точкой больше, чем с области больших чисел)\n",
    "* для линейных моделей: интерпретация весов при признаках как меры их значимости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый популярный способ масштабирования - нормализация: вычитание среднего из каждого признака и деление на стандартное отклонение. Реализация в sklearn (нормировать бинарные признаки не нужно):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = preprocessing.StandardScaler()\n",
    "X_real_norm_np = normalizer.fit_transform(X_no_mis)\n",
    "X_real_norm_pd = pd.DataFrame(data=X_real_norm_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй популярный способ: вычитание минимума из каждого признака, а затем деление на разницу максимального и минимального значения. Реализация в sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_scaler = preprocessing.MinMaxScaler()\n",
    "X_mm_scaled = mm_scaler.fit_transform(X_no_mis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объдиняем категориальные и вещественные признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X = pd.concat([X_real_norm_pd, X_cat_pd], axis=1)\n",
    "X.columns = np.array([\"f\"+str(i) for i in range(X.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление полиномиальных признаков\n",
    "Генерировать все полиномиальные признаки можно следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_feat = preprocessing.PolynomialFeatures(degree=2, include_bias=False) # не включать константный признак\n",
    "X_pol = pol_feat.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X.shape, X_pol.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что новая матрциа может занимать очень много памяти. Генерация полиномиальных признаков нужна, например, в случае, если вы хотите с помощью линейной регрессии настраивать полиномиальную модель зависимости целевого признака от данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции потерь в регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Функционал качества в задачах обучения с учителем обычно задается в виде суммы по объектам выборки:\n",
    "$$Q(a) = \\frac 1 \\ell \\sum_{i=1}^\\ell L(y_i, a(x_i)),$$\n",
    "где $L(\\cdot, \\cdot)$ - функция потерь, задающая штраф за разницу между предсказанием и истинным значением целевого признака. Свойства функции потерь:\n",
    "* $L(y_i, a(x_i)) \\geqslant 0$;\n",
    "* $L(y_i, y_i) = 0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как отмечалось на первой лекции, функционал качества должен в первую очередь отвечать требованиям заказчика, при этом математические свойства функции потерь могут быть неудобны для оптимизации. \n",
    "\n",
    "__Пример:__ если мы не различаем маленькие ошибки (между 0.01 и 0.1 нет особой разницы), но зато не хотим получать большие ошибки, можно использовать следующую функцию потерь:\n",
    "\n",
    "$$L(y_i, a(x_i)) = [| y_i - a(x_i) | < \\varepsilon],$$ $\\varepsilon$ - допустимая разница между предсказанием и фактом.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Среднеквадратичная и средняя абсолютная ошибка\n",
    "Кроме требований заказчика, функционал качества должен учитывать математические особенности модели, например устойчивость к шумовым объектам. В линейной регрессии Mean Squared Error: $L(y_i, a(x_i)) = (a(x_i) - y_i)^2$ не обладает этим свойством, потому что задает очень большие штрафы за большие отклонения от фактического значения. \n",
    "\n",
    "Рассмотрим это явление на примере. Выберем один признак, от которого целевой признак (имеющий индекс 15 в матрице X) зависит практически линейно. Добавим к выборке два объекта-выброса и посмотрим, как изменится оптимизированная на MSE прямая."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression as LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_subset \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf7\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf15\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      2\u001b[0m X_subset_modified \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((X_subset, [[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m90\u001b[39m], [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m50\u001b[39m]])) \u001b[38;5;66;03m# добавление двух шумовых точек\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X_subset = X[[\"f7\", \"f15\"]].values\n",
    "X_subset_modified = np.vstack((X_subset, [[1, 90], [2, 50]])) # добавление двух шумовых точек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_points_and_plot_line_MSE(X_subset):\n",
    "    plt.scatter(X_subset[:, 0], X_subset[:, 1])   # визуализируем точки\n",
    "    lr = LR()\n",
    "    lr.fit(X_subset[:, 0][:, np.newaxis], X_subset[:, 1])  # найдем веса линейной модели\n",
    "    grid = np.linspace(-2, 6, 100)\n",
    "    line = lr.predict(grid[:, np.newaxis])\n",
    "    plt.plot(grid, line)   # визуализируем прямую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter_points_and_plot_line_MSE(X_subset)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter_points_and_plot_line_MSE(X_subset_modified)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из-за шумовых объектов прямая достаточно сильно изменила наклон. Поэтому вместо MSE часто используют Mean Absoulte Error: $L(y_i, a(x_i)) = |a(x_i) - y_i|$:\n",
    "\n",
    "Теперь обучим регрессию, оптимизируя MAE. В sklearn такая регрессия не реализована, но можно использовать модуль statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_points_and_plot_line_MAE(X_subset):\n",
    "    mod = smf.quantreg('f15 ~ f7', pd.DataFrame(data=X_subset, columns=[\"f7\", \"f15\"])) # задаеем зависимость и передаем данные\n",
    "    res = mod.fit(q=0.5)\n",
    "    plt.scatter(X_subset[:, 0], X_subset[:, 1])   # визуализируем точки\n",
    "    grid = np.linspace(-2, 6, 100)\n",
    "    plt.plot(grid, grid * res.params[\"f7\"] + res.params[\"Intercept\"])   # визуализируем прямую\n",
    "    return mod, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "model, result = scatter_points_and_plot_line_MAE(X_subset)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.subplot(1, 2, 2)\n",
    "model, result = scatter_points_and_plot_line_MAE(X_subset_modified)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прямая не изменила направление из-за выбросов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем добавить больше шумовых объектов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subset_modified_twice = np.vstack((X_subset_modified, np.random.randint(5, size=60).reshape(-1, 2)*[1, 30])) # добавление двух шумовых точек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "model, result = scatter_points_and_plot_line_MAE(X_subset)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.subplot(1, 2, 2)\n",
    "model, result = scatter_points_and_plot_line_MAE(X_subset_modified_twice)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прямая немного изменила наклон, когда мы добавили 30 (почти 15%) шумовых точек."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим некоторые свойства MSE и MAE.\n",
    "\n",
    "Пусть алгоритм возвращает константный ответ: $a(x) = C$. Такие алгоритмы используются, когда для одного объекта известны несколько различных значений одного целевого признака (например, суммы покупок в одном магазине).\n",
    "\n",
    "__Задача.__ Найдите $C$, минимизирующий среднеквадратичную ошибку.\n",
    "\n",
    "_Решение._ $$MSE(C) = \\frac{1}{\\ell} \\sum_{i=1}^\\ell (C - y_i)^2$$\n",
    "$$\\frac{\\partial MSE (C)}{\\partial C} = \\frac{1}{\\ell} \\sum_{i=1}^\\ell 2 (C - y_i) = 2 C - \\frac{1}{\\ell} \\sum_{i=1}^\\ell 2 y_i = 0$$\n",
    "$$C = \\frac 1 \\ell \\sum_{i=1}^\\ell y_i$$.\n",
    "\n",
    "__Задача.__ Найдите $C$, минимизирующий среднюю абсолютную ошибку.\n",
    "\n",
    "_Решение._ $$MAE(C) =  \\frac{1}{\\ell} \\sum_{i=1}^\\ell |C - y_i|$$\n",
    "\n",
    "Покажем, что минимум MAE достигается при $C = median(y_1, \\dots, y_\\ell) = m.$ Рассмотрим $C < m$.\n",
    "\n",
    "$$|y_i - C| - |y_i - m| = \\begin{cases} C - m, y_i < m  \\\\ - (C + m - 2 y_i), C \\leqslant y_i \\leqslant m \\\\ - (C - m), y_i > m \\end{cases}$$\n",
    "$$|y_i - C| - |y_i - m| \\geqslant - (C - m) + 2(C - m) [y_i \\leqslant m]$$\n",
    "Суммируем по i:\n",
    "$$\\ell MAE(C) - \\ell MAE(m) \\geqslant - \\ell (C - m) + 2 (C - m) \\sum_{i=1}^\\ell [y_i \\leqslant m]$$\n",
    "\n",
    "Так как m - медиана, $\\sum_{i=1}^\\ell [y_i \\leqslant m] \\geqslant \\frac \\ell 2$. Тогда\n",
    "\n",
    "$$\\ell MAE(C) - \\ell MAE(m) \\geqslant - \\ell (C - m) + 2 (C - m) \\frac \\ell 2 = 0.$$\n",
    "\n",
    "Итак, для $C < m$ выполняется $MAE(C) \\geqslant MAE(m)$. Аналогично показывается, что при для $C > m$ выполняется $MAE(C) \\geqslant MAE(m)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку средняя абсолютная ошибка не является дифференцируемой по $w$ функцией, оптимизировать ее напрямую методом градиентного спуска не удастся. Для этого используются субградиентные или другие методы. Один из способов оптимизации MAE будет рассмотрен ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huber Loss\n",
    "Иногда используют \"гибрид\" MAE и MSE, который, как и MAE, устойчив к шумовым объектам, и как и MSE, мало штрафует малые отклонения от фактического значени целевого признака - Huber Loss:\n",
    "$$L(y_i, a(x_i)) = \\phi_\\varepsilon(a(x_i) - y_i)$$\n",
    "$$\\phi_\\varepsilon(z) = \\begin{cases} \\frac 1 2 z^2, - \\varepsilon < z < \\varepsilon, \\\\\\varepsilon (|z| - \\frac 1 2 \\varepsilon), иначе \\\\ \\end{cases}$$\n",
    "\n",
    "Легко проверить, что у этой функции существует непрерывная первая проиводная во всех точках.\n",
    "\n",
    "Оптимизация Huber Loss реализована в sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import HuberRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В некоторых задачах штраф за ошибку зависит не только от величины абсолютного отклонения от фактического значения, но и от знака этого отклонения. Например, лучше предсказать спрос больше, чем будет по факту, чем меньше, потому что в первом случае будет потеряна прибыль. В этом случае используется квантильная регрессия со следующей функцией потерь:\n",
    "$$L(y_i, a(x_i)) = \\rho_\\tau(y_i - x_i^T w),$$\n",
    "$$\\rho_\\tau(z) = \\begin{cases} \\tau z, \\quad z > 0, \\\\ (\\tau - 1) z, \\quad z \\leqslant 0 \\end{cases}$$\n",
    "Параметр $\\tau$ влияет на то, насколько различаются штрафы за положительную и отрицательную разницу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "grid = np.linspace(-3, 3, 100)\n",
    "tau_list = [0.1, 0.5, 0.8, 0.9]\n",
    "for tau in tau_list:\n",
    "    plt.plot(grid, tau * grid * (grid > 0) + (tau - 1) * grid * (grid <= 0), label=r\"$\\tau = \" + str(tau) + r\"$\")\n",
    "plt.xlabel(r'$z = y_i - a(x_i)$', size=20)\n",
    "plt.ylabel(r'$\\mathscr{L}(z)$', size=20)\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изобразим график квантильной функции потерь вместе с другими рассмотренными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "grid = np.linspace(-3, 3, 100)\n",
    "quantile_tau = 0.2\n",
    "mse_loss = grid ** 2\n",
    "mae_loss = np.abs(grid)\n",
    "huber_loss = 0.5 * mse_loss * (grid >= -1) * (grid <= 1) + (mae_loss - 0.5) * (grid < -1) + (mae_loss - 0.5)  * (grid > 1)\n",
    "quantile_loss = quantile_tau * grid * (grid > 0) + (quantile_tau - 1) * grid * (grid <= 0)\n",
    "plt.plot(grid, mae_loss, label=\"Absolute Loss\")\n",
    "plt.plot(grid, mse_loss, label=\"Quadratic Loss\")\n",
    "plt.plot(grid, huber_loss, label=\"Huber Loss\")\n",
    "plt.plot(grid, quantile_loss, label=\"Quantile Loss\")\n",
    "plt.xlabel(\"$y_i - a(x_i)$\")\n",
    "plt.ylabel(\"$L(y_i, a(x_i))$\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задача.__ Укажите параметр $\\tau$, при котором обучение квантильной регрессии равносильно оптимизации MAE.\n",
    "\n",
    "_Решение._ При $\\tau = \\frac 1 2$ $$\\rho_\\tau(x) = \\frac 1 2 |x|$$ и $L(y_i, a(x_i)) = \\frac 1 2 MAE$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение квантильной регрессии как задача линейного программирования\n",
    "Как и в случае с MAE, функция потерь не дифференцируема в 0. Однако задачу оптимизации MAE можно свести к задаче линейного программирования, для которой известны эффективные алгоритмы решения ([Симплекс-метод](https://ru.wikipedia.org/wiki/%D0%A1%D0%B8%D0%BC%D0%BF%D0%BB%D0%B5%D0%BA%D1%81-%D0%BC%D0%B5%D1%82%D0%BE%D0%B4)). Задача линейного программирования в общем виде задается  следующем виде:\n",
    "$$\\langle c, x \\rangle \\rightarrow \\min_{x}$$\n",
    "$$Ax = b$$\n",
    "$$x \\geqslant 0$$\n",
    "\n",
    "__Задача.__ Рассмотрим задачу оптимизации $$\\sum_{i=1}^\\ell \\rho_\\tau(y_i - x_i^T w) \\rightarrow \\min _{w}.$$\n",
    "Сведите эту задачу к задаче линейного программирования.\n",
    "\n",
    "_Решение._ Введем переменные:\n",
    "$$e_i = y_i - x_i^T w$$\n",
    "$$u_i = max\\{e_i, 0\\} \\geqslant 0$$\n",
    "$$v_i = max\\{-e_i, 0\\} \\geqslant 0$$\n",
    "Тогда $u_i - v_i = e_i$,\n",
    "\n",
    "$$ \\rho_\\tau(y_i - x_i^T w) = \\rho_\\tau(e_i) = \\rho_\\tau(u_i - v_i) = \\tau u_i + (1 - \\tau) v_i. $$\n",
    "Последний переход можно проверить непосрдственно. Например, если $e_i \\geqslant 0$, то $v_i = 0$,\n",
    "$$\\rho_\\tau(e_i) = \\tau (u_i - v_i) = \\tau (u_i - v_i) + v_i = \\tau u_i + (1 - \\tau) v_i.$$ Аналогично при $e_i < 0$.\n",
    "\n",
    "Функционал качества:\n",
    "$$\\sum_{i=1}^\\ell \\rho_\\tau(y_i - x_i^T w) = \\sum_{i=1}^\\ell \\bigl (\\tau u_i + (1 - \\tau) v_i \\bigr) = \\tau \\sum_{i=1}^\\ell u_i + (1 - \\tau) \\sum_{i=1}^\\ell v_i = \\tau \\langle 1, u \\rangle + (1 - \\tau) \\langle 1, v \\rangle ,$$\n",
    "$1 = (1, \\dots, 1) \\in R^\\ell$, $u = (u_1, \\dots, u_\\ell$), $v = (v_1, \\dots, v_\\ell)$.\n",
    "\n",
    "Задача линейного программирования:\n",
    "\n",
    "$$\\tau \\langle 1, u \\rangle + (1 - \\tau) \\langle 1, v \\rangle \\rightarrow \\min_{u, v, w}$$\n",
    "$$y - X w = u - v$$\n",
    "$$u \\geqslant 0, \\quad v \\geqslant 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проследим наклон прямой в нашей одномерной задаче регрессии при изменении $\\tau$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_subset[:, 0], X_subset[:, 1])\n",
    "grid = np.linspace(-2, 6, 100)\n",
    "mod = smf.quantreg('f15 ~ f7', pd.DataFrame(data=X_subset, columns=[\"f7\", \"f15\"]))\n",
    "for q in np.arange(0.1, 1, 0.1):\n",
    "    res = mod.fit(q=q)\n",
    "    plt.plot(grid, grid * res.params[\"f7\"] + res.params[\"Intercept\"], label=\"q = \"+str(q))\n",
    "plt.legend(loc=(1.1, 0.1))\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vowpal wabbit\n",
    "Мы увидели, что в python для оптимизации разных функционалов качества приходится искать отдельные модули. Кроме того, для очень больших матриц объекты-признаки python-методы могут быть неэффективны. В сообществе специалистов по машинному обучению популярна система [vowpal wabbit](https://github.com/JohnLangford/vowpal_wabbit/wiki), позволяющая оптимизировать разные функции потерь и предоставляющая пользователю интерфейс для командной строки.\n",
    "\n",
    "В vowpal wabbit реализован эффективный и масштабируемый онлайн-алгоритм для оптимизации линейной модели.\n",
    "\n",
    "[Входные данные](https://github.com/JohnLangford/vowpal_wabbit/wiki/Input-format) должны быть представлены с виде текстового файла, каждая строка - отдельный объект. Формат строки:\n",
    "\n",
    "      [Label] [Importance] [Base] [Tag]|Namespace Features |Namespace Features ... |Namespace Features\n",
    "где\n",
    "* Label - значение целевого признака\n",
    "* Importance - вес объекта в функционале качества (коэффициент, на который домножается функция потерь)\n",
    "* Tag - идентификатор\n",
    "* Namespace задает группу признаков (пространство имен)\n",
    "* Признаки перечисляются через пробел в виде признак:значение, :1 можно опускать (если какой-то признак в одном пространстве имен повторяется, то его значения суммируются)\n",
    "\n",
    "**Пример**:\n",
    "123 10 |integer 1:0.43 5:2.1 age:20 |text some raw text here age:120\n",
    "\n",
    "Корректность формата входных данных можно проверить при помощи [VW validator](http://hunch.net/%7Evw/validate.html).\n",
    "\n",
    "Интерфейс командной строки подробно описан на [Github-Wiki проекта](https://github.com/JohnLangford/vowpal_wabbit/wiki/Command-line-arguments).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные в указанном формате нужно сохранить в файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для записи датафрейма в vowpal wabbit\n",
    "def convert_df_to_vw(df, target_col, vw_path):\n",
    "    target = df[target_col]\n",
    "    feature_cols = df.columns.drop(target_col)\n",
    "    with open(vw_path, \"w\") as fout:\n",
    "        for idx in df.index:\n",
    "            fout.write(str(target[idx])+\" |features\")\n",
    "            features = df[feature_cols].loc[idx]\n",
    "            for feature in features.index:\n",
    "                if features[feature] != 0:\n",
    "                    fout.write(\" \"+str(feature)+\":\"+str(features[feature]))\n",
    "            fout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(X, test_size = 0.2)\n",
    "convert_df_to_vw(X_train, \"f15\", \"train.txt\")\n",
    "convert_df_to_vw(X_test, \"f15\", \"test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример запуска обучения регрессии на MAE vowpal wabbit с сохранением обученной модели в model.vw (! в начале строки сообщает,  что это команда для командной строки):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "! vw --data train.txt --loss_function quantile --quantile_tau 0.5 -f model.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другие полезные опции:\n",
    "* --passes 10 : число проходов по данным во время обучения\n",
    "* --quadratic ab: сгенерировать все парные признаки, где первый признак берется из пространств с именем \"a\\*\", а второй — из \"b*\"\n",
    "* --cubic abc : кубические признаки\n",
    "* --ignore a : игнорировать признаки из namespace, начинающихся с a\n",
    "* --keep ab : использовать только признаки из namespace, начинающихся с a и b\n",
    "* --l1 1.0 : коэффициент при L1-регуляризаторе\n",
    "* --l2 1.0 : коэффициент при L2-регуляризаторе\n",
    "* --minibatch 5 : число объектов в мини-батче при обучении\n",
    "* параметры градиентного шага: \n",
    "$$w^{(t+1)} = w^t - \\alpha_t \\frac{\\partial}{\\partial w} Q(x_{i_t}),$$\n",
    "$$\\alpha_t = s \\left( \\frac{i}{i + t} \\right)^p,$$\n",
    "где \n",
    "    * -l s\n",
    "    * -initial_t i\n",
    "    * -power_t p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Сделать предсказания для новых объектов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!`vw --data test.txt -t -i model.vw --loss_function quantile --quantile_tau 0.5 -r raw_predictions.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
